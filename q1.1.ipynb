{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e06534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, InceptionV3, MobileNet, EfficientNetB0\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the images are in a directory with subfolders for each class\n",
    "train_dir = 'path/to/train'\n",
    "val_dir = 'path/to/validation'\n",
    "\n",
    "# Image parameters\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Training and validation generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b87719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(base_model, preprocess_input, num_classes):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# ResNet50\n",
    "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "resnet_model = create_model(resnet_base, resnet_preprocess, num_classes)\n",
    "\n",
    "# VGG16\n",
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg_model = create_model(vgg_base, vgg_preprocess, num_classes)\n",
    "\n",
    "# InceptionV3 (GoogleNet)\n",
    "inception_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "inception_model = create_model(inception_base, inception_preprocess, num_classes)\n",
    "\n",
    "# MobileNet\n",
    "mobilenet_base = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "mobilenet_model = create_model(mobilenet_base, mobilenet_preprocess, num_classes)\n",
    "\n",
    "# EfficientNetB0\n",
    "efficientnet_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "efficientnet_model = create_model(efficientnet_base, efficientnet_preprocess, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Training ResNet50 model\n",
    "history_resnet = resnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Example: Training VGG16 model\n",
    "history_vgg = vgg_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Example: Training InceptionV3 model\n",
    "history_inception = inception_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Example: Training MobileNet model\n",
    "history_mobilenet = mobilenet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Example: Training EfficientNetB0 model\n",
    "history_efficientnet = efficientnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, model_name):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(f'{model_name} Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f'{model_name} Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "# Plotting results for each model\n",
    "plot_history(history_resnet, 'ResNet50')\n",
    "plot_history(history_vgg, 'VGG16')\n",
    "plot_history(history_inception, 'InceptionV3')\n",
    "plot_history(history_mobilenet, 'MobileNet')\n",
    "plot_history(history_efficientnet, 'EfficientNetB0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8e050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
